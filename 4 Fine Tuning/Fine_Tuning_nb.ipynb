{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise/project we will be using the `recipies.jsonl` file as our dataset. As for the `messages.jsonl` file you can use it to perform fine tuning directly in the console UI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source of this project is this project from OpenAI's cookbook:\n",
    "\n",
    "https://cookbook.openai.com/examples/how_to_finetune_chat_models\n",
    "\n",
    "The only modification we have done is in the dataset. I have provided you directly with the dataset to avoid some initial data preparation steps done in the cookbook project\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to use the latest version of the openai python package\n",
    "!pip install --upgrade --quiet openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to add OPENAI_API_KEY as your env var before running this code block\n",
    "import openai\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "- Load and split the data into training and validation splits.\n",
    "- The `recipies.jsonl` file has 122 examples which should be more than enough to perform the Project.\n",
    "- We will use 80 examples for training and the rest 42 for validation purpose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'role': 'system', 'content': 'You are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.'}, {'role': 'user', 'content': 'Title: Caprese Salad\\n\\nIngredients: [\"3 ripe tomatoes, sliced\", \"1 cup fresh mozzarella cheese, sliced\", \"1/4 cup fresh basil leaves\", \"1/4 cup balsamic vinegar\", \"1/4 cup olive oil\", \"Salt and pepper to taste\"]\\n\\nGeneric ingredients: '}, {'role': 'assistant', 'content': '[\"tomatoes\", \"mozzarella cheese\", \"basil leaves\", \"balsamic vinegar\", \"olive oil\", \"salt\", \"pepper\"]'}]}\n",
      "<class 'dict'>\n",
      "122\n"
     ]
    }
   ],
   "source": [
    "dataList = []\n",
    "with open(\"recipies.jsonl\") as f:\n",
    "     dataList = [eval(line.rstrip('\\n')) for line in f]\n",
    "\n",
    "print(dataList[0])\n",
    "print(type(dataList[0]))\n",
    "print(len(dataList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 80 examples\n",
      "Validation set has 42 examples\n"
     ]
    }
   ],
   "source": [
    "trainingSet, validationSet = dataList[0:80], dataList[80:]\n",
    "\n",
    "print(f\"Training set has {len(trainingSet)} examples\")\n",
    "print(f\"Validation set has {len(validationSet)} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload data to OpenAI API\n",
    "\n",
    "We then need to save our data as `.jsonl` files, with each line being one training example conversation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def write_jsonl(data_list: list, filename: str) -> None:\n",
    "    with open(filename, \"w\") as out:\n",
    "        for ddict in data_list:\n",
    "            jout = json.dumps(ddict) + \"\\n\"\n",
    "            out.write(jout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_name = \"training_data.jsonl\"\n",
    "write_jsonl(trainingSet, training_file_name)\n",
    "\n",
    "validation_file_name = \"validation_data.jsonl\"\n",
    "write_jsonl(validationSet, validation_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file ID: file-HKSM9dANdGKLAl6WEjtOl51m\n",
      "Validation file ID: file-OWsytGqjGpFAkU4O2woBZsb6\n"
     ]
    }
   ],
   "source": [
    "def upload_file(file_name: str, purpose: str) -> str:\n",
    "    with open(file_name, \"rb\") as file_fd:\n",
    "        response = client.files.create(file=file_fd, purpose=purpose)\n",
    "    return response.id\n",
    "\n",
    "\n",
    "training_file_id = upload_file(training_file_name, \"fine-tune\")\n",
    "validation_file_id = upload_file(validation_file_name, \"fine-tune\")\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-wCfRaTBkkH6eU22hmjELFGzy\n",
      "Status: validating_files\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"gpt-3.5-turbo-0125\"\n",
    "\n",
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=MODEL,\n",
    "    suffix=\"recipe-ner\",\n",
    "   hyperparameters={\n",
    "      \"n_epochs\": 2\n",
    "    }\n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-wCfRaTBkkH6eU22hmjELFGzy\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created fine-tuning job: ftjob-wCfRaTBkkH6eU22hmjELFGzy\n",
      "Validating training file: file-HKSM9dANdGKLAl6WEjtOl51m and validation file: file-OWsytGqjGpFAkU4O2woBZsb6\n",
      "Files validated, moving job to queued state\n",
      "Fine-tuning job started\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.list_events(job_id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Tuning Job Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model ID: ft:gpt-3.5-turbo-0125:personal:recipe-ner:9qrgclr6\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "\n",
    "if fine_tuned_model_id is None:\n",
    "    raise RuntimeError(\n",
    "        \"Fine-tuned model ID not found. Your job has likely not been completed yet.\"\n",
    "    )\n",
    "\n",
    "print(\"Fine-tuned model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_messages = [\n",
    "    {'role': 'system', 'content': 'You are a helpful recipe assistant. You are to extract the generic ingredients from each of the recipes provided.'},\n",
    "    {'role': 'user', 'content': 'Title: Beef Brisket\\n\\nIngredients: [\"4 lb. beef brisket\", \"1 c. catsup\", \"1 c. water\", \"1/2 onion, minced\", \"2 Tbsp. cider vinegar\", \"1 Tbsp. prepared horseradish\", \"1 Tbsp. prepared mustard\", \"1 tsp. salt\", \"1/2 tsp. pepper\"]\\n\\nGeneric ingredients: '}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"beef brisket\", \"catsup\", \"water\", \"onion\", \"cider vinegar\", \"horseradish\", \"mustard\", \"salt\", \"pepper\"]\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=fine_tuned_model_id, messages=test_messages, temperature=0, max_tokens=500\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
